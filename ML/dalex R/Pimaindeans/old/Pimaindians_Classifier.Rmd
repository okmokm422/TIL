# Pimaindean Dataset Analutics

```{r}
.libPaths()
```


- [dataset](https://www.kaggle.com/uciml/pima-indians-diabetes-database)

# 1. ライブラリ読み込み

```{r results = 'hide'}
# dataframe操作パッケージ
library(dplyr)
# 欠損値の補完パッケージ
library(ForImp)
# train_test_split/dummyVarsを行うパッケージ
library(caret)
# Keras
library(keras)
# lightgbm
# library(lightgbm)
```


# 2. データセット読み込み
```{r}
df <- read.csv('diabetes.csv')
head(df, n = 5)
```

# 3. データ概要の確認

```{r}
summary(df)
```

```{r}
print(nrow(df)) # 行
print(ncol(df)) # 列
```

```{r}
colnames(df)
```

```{r}
na_df <- apply(df, 2, function(y) any(is.na(y)))
na_df
```

```{r}
null_df <- sapply(df, function(y) any(is.null(y)))
null_df
```

# 4. 前処理 

## 4-1. データの分割

```{r}
set.seed(333)
# 分割したレコード（今回は80%）の行番号を受け取る
# データの分布を維持したまま分割
train_index <- createDataPartition(df$Outcome, p=0.8, list=FALSE)
head(train_index, n = 15)
```

```{r}
dim(train_index)
```


```{r results = 'hide'}
X_train <- select(.data = df[train_index, ], -Outcome)
y_train <- select(.data = df[train_index, ], Outcome)
X_test <- select(.data = df[-train_index, ], -Outcome)
y_test <- select(.data = df[-train_index, ], Outcome)
```


```{r}
dim(X_train)
dim(y_train)
dim(X_test)
dim(y_test)
```

## 4-2. 数値カラムとカテゴリ変数カラムに分割
```{r results = 'hide'}
numerical_features = c('Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age')
categolical_features = c(NULL)
```

### 4-2-1. 数値カラムに欠損値処理(中央値で穴埋め)・標準化
```{r results = 'hide'}
# 中央値で補完
medianimp(X_train[, numerical_features])
medianimp(X_test[, numerical_features])
# 標準化
scale(X_train[, numerical_features])
scale(X_test[, numerical_features])
```

### 4-2-2. カテゴリ変数カラムに欠損値処理（missingで穴埋め）・OneHot処理

```{r results = 'hide'}
## missingで補完
# X_train[is.na(X_train[, categolical_features])] <- 'missing'
# X_train[is.na(X_train[, categolical_features])] <- 'missing'
# X_test[is.null(X_test[, categolical_features])] <- 'missing'
# X_test[is.null(X_test[, categolical_features])] <- 'missing'
## One-Hot Encoding
# dummy_model <- dummyVars(~categolical_features, data=X_train, fullRank=FALSE)
# dummy_vars <- predict(dummy_model, X_train)
# X_train <- data.frame(X_train, dummy_vars)
```



# 5. KerasでDNNモデル作成

```{r results = 'hide'}
X_train <- X_train %>% as.matrix() %>% lapply(as.double)
y_train <- y_train %>% as.matrix() %>% lapply(as.double)
X_test <- X_test %>% as.matrix() %>% lapply(as.double)
y_test <- y_test %>% as.matrix() %>% lapply(as.double)
```

```{r}
typeof(X_train)
typeof(y_train)
typeof(X_test)
typeof(y_test)
```


```{r}
model = keras_model_sequential()
# 重みの初期化方法確認！！
model %>%
  layer_dense(units=32, activation="relu", input_shape = c(dim(X_train)[2]), kernel_initializer = 'glorot_normal') %>%
  layer_dropout(rate=0.1) %>%
  layer_dense(units=16, activation="relu", input_shape = 32, kernel_initializer = 'glorot_normal') %>%
  layer_dropout(rate=0.1) %>%
  layer_dense(units=8, activation = "relu", input_shape = 16, kernel_initializer = 'glorot_normal') %>% 
  layer_dense(units=4, activation = "relu", input_shape = 8, kernel_initializer = 'glorot_normal') %>% 
  layer_dense(units=1, activation = "sigmoid", input_shape = 4, kernel_initializer = 'glorot_normal')
```

```{r}
model %>% compile(
  loss = "binary_crossentropy",
  optimizer = 'rmsprop',
  metrics = c("accuracy")
)
```


```{r}
model %>% fit(x = X_train , y = y_train)
```

