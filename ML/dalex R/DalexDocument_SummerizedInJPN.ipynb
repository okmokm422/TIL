{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Dalex Document link](https://pbiecek.github.io/ema/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1.-Introduction\" data-toc-modified-id=\"1.-Introduction-1\">1. Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.1-Notes-to-readers\" data-toc-modified-id=\"1.1-Notes-to-readers-1.1\">1.1 Notes to readers</a></span></li><li><span><a href=\"#1.2-The-aim-of-the\" data-toc-modified-id=\"1.2-The-aim-of-the-1.2\">1.2 The aim of the</a></span></li><li><span><a href=\"#1.3- A-bit-of-philosophy:-three-laws-of-model-explanation\" data-toc-modified-id=\"1.3- A-bit-of-philosophy:-three-laws-of-model-explanation-1.3\">1.3  A bit of philosophy: three laws of model explanation</a></span></li><li><span><a href=\"#1.4- The-structure-of-this-book\" data-toc-modified-id=\"1.4- The-structure-of-this-book-1.4\">1.4  The structure of this book</a></span></li><li><span><a href=\"#1.5- Terminology\" data-toc-modified-id=\"1.5- Terminology-1.5\">1.5  Terminology</a></span></li><li><span><a href=\"#1.6 -Glass-box-models-vs. black-box-models\" data-toc-modified-id=\"1.6 -Glass-box-models-vs. black-box-models-1.6\">1.6  Glass-box models vs. black-box models</a></span></li><li><span><a href=\"#1.7 -Model-agnostic-vs. model-specific-approach\" data-toc-modified-id=\"1.7 -Model-agnostic-vs. model-specific-approach-1.7\">1.7  Model-agnostic vs. model-specific approach</a></span></li><li><span><a href=\"#1.8- What-is-in-this-book-and-what-is-not\" data-toc-modified-id=\"1.8- What-is-in-this-book-and-what-is-not-1.8\">1.8  What is in this book and what is not</a></span></li><li><span><a href=\"#1.9- Acknowledgements\" data-toc-modified-id=\"1.9- Acknowledgements-1.9\">1.9  Acknowledgements</a></span></li></ul></li><li><span><a href=\"#2 -Model-Development\" data-toc-modified-id=\"2 -Model-Development-2\">2  Model Development</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1 Introduction\" data-toc-modified-id=\"2.1 Introduction-2.1\">2.1 Introduction</a></span></li><li><span><a href=\"#2.2-The-Process\" data-toc-modified-id=\"2.2-The-Process-2.2\">2.2 The Process</a></span></li><li><span><a href=\"#2.3-Notation\" data-toc-modified-id=\"2.3-Notation-2.3\">2.3 Notation</a></span></li><li><span><a href=\"#2.4-Data-exploration\" data-toc-modified-id=\"2.4-Data-exploration-2.4\">2.4 Data exploration</a></span></li><li><span><a href=\"#2.5-Model-training\" data-toc-modified-id=\"2.5-Model-training-2.5\">2.5 Model training</a></span></li><li><span><a href=\"#2.6-Model-understanding\" data-toc-modified-id=\"2.6-Model-understanding-2.6\">2.6 Model understanding</a></span></li></ul></li><li><span><a href=\"#6-Introduction-to-Instance-Level-Exploration\" data-toc-modified-id=\"6-Introduction-to-Instance-Level-Exploration-3\">6 Introduction to Instance Level Exploration</a></span></li><li><span><a href=\"#7-Break-down-Plots-for-Additive-Attributions\" data-toc-modified-id=\"7-Break-down-Plots-for-Additive-Attributions-4\">7 Break-down Plots for Additive Attributions</a></span><ul class=\"toc-item\"><li><span><a href=\"#7.1-Intuition\" data-toc-modified-id=\"7.1-Intuition-4.1\">7.1 Intuition</a></span></li><li><span><a href=\"#7.2-Method\" data-toc-modified-id=\"7.2-Method-4.2\">7.2 Method</a></span><ul class=\"toc-item\"><li><span><a href=\"#7.2.1-Break-down-for-linear-models（線形モデル（加法モデル？）について）\" data-toc-modified-id=\"7.2.1-Break-down-for-linear-models（線形モデル（加法モデル？）について）-4.2.1\">7.2.1 Break-down for linear models（線形モデル（加法モデル？）について）</a></span></li><li><span><a href=\"#7.2.2-Break-down-for-a-general-case（線形モデル外も含む一般化）\" data-toc-modified-id=\"7.2.2-Break-down-for-a-general-case（線形モデル外も含む一般化）-4.2.2\">7.2.2 Break-down for a general case（線形モデル外も含む一般化）</a></span></li></ul></li><li><span><a href=\"#7.3-Example:-Titanic-data\" data-toc-modified-id=\"7.3-Example:-Titanic-data-4.3\">7.3 Example: Titanic data</a></span></li><li><span><a href=\"#7.4-Pros-and-cons\" data-toc-modified-id=\"7.4-Pros-and-cons-4.4\">7.4 Pros and cons</a></span></li></ul></li><li><span><a href=\"#8-Break-down-Plots-for-Interactions-(iBreak-down-Plots)\" data-toc-modified-id=\"8-Break-down-Plots-for-Interactions-(iBreak-down-Plots)-5\">8 Break-down Plots for Interactions (iBreak-down Plots)</a></span><ul class=\"toc-item\"><li><span><a href=\"#8.1-Intuition\" data-toc-modified-id=\"8.1-Intuition-5.1\">8.1 Intuition</a></span></li><li><span><a href=\"#8.2-Method\" data-toc-modified-id=\"8.2-Method-5.2\">8.2 Method</a></span></li><li><span><a href=\"#8.3-Example:-Titanic-data\" data-toc-modified-id=\"8.3-Example:-Titanic-data-5.3\">8.3 Example: Titanic data</a></span></li></ul></li><li><span><a href=\"#9-Shapley-Additive-Explanations-(SHAP)-and-Average-Variable-Attributions\" data-toc-modified-id=\"9-Shapley-Additive-Explanations-(SHAP)-and-Average-Variable-Attributions-6\">9 Shapley Additive Explanations (SHAP) and Average Variable Attributions</a></span><ul class=\"toc-item\"><li><span><a href=\"#9.1-Intuition\" data-toc-modified-id=\"9.1-Intuition-6.1\">9.1 Intuition</a></span></li><li><span><a href=\"#9.2-Method\" data-toc-modified-id=\"9.2-Method-6.2\">9.2 Method</a></span></li><li><span><a href=\"#9.3-Example:-Titanic-data\" data-toc-modified-id=\"9.3-Example:-Titanic-data-6.3\">9.3 Example: Titanic data</a></span></li><li><span><a href=\"#9.4-Pros-and-cons\" data-toc-modified-id=\"9.4-Pros-and-cons-6.4\">9.4 Pros and cons</a></span></li><li><span><a href=\"#9.5-Code-snippets-for-R\" data-toc-modified-id=\"9.5-Code-snippets-for-R-6.5\">9.5 Code snippets for R</a></span></li></ul></li><li><span><a href=\"#10-Local-Interpretable-Model-agnostic-Explanations-(LIME)\" data-toc-modified-id=\"10-Local-Interpretable-Model-agnostic-Explanations-(LIME)-7\">10 Local Interpretable Model-agnostic Explanations (LIME)</a></span><ul class=\"toc-item\"><li><span><a href=\"#10.1-Introduction\" data-toc-modified-id=\"10.1-Introduction-7.1\">10.1 Introduction</a></span></li><li><span><a href=\"#10.2-Intuition\" data-toc-modified-id=\"10.2-Intuition-7.2\">10.2 Intuition</a></span></li><li><span><a href=\"#10.3-Method\" data-toc-modified-id=\"10.3-Method-7.3\">10.3 Method</a></span><ul class=\"toc-item\"><li><span><a href=\"#10.3.1-Interpretable-data-representation\" data-toc-modified-id=\"10.3.1-Interpretable-data-representation-7.3.1\">10.3.1 Interpretable data representation</a></span></li><li><span><a href=\"#10.3.3-Developing-the-glass-box-model\" data-toc-modified-id=\"10.3.3-Developing-the-glass-box-model-7.3.2\">10.3.3 Developing the glass-box model</a></span></li></ul></li><li><span><a href=\"#10.4-Example:-Titanic-data\" data-toc-modified-id=\"10.4-Example:-Titanic-data-7.4\">10.4 Example: Titanic data</a></span></li><li><span><a href=\"#10.5-Pros-and-cons\" data-toc-modified-id=\"10.5-Pros-and-cons-7.5\">10.5 Pros and cons</a></span></li></ul></li><li><span><a href=\"#11-Ceteris-paribus-Profiles\" data-toc-modified-id=\"11-Ceteris-paribus-Profiles-8\">11 Ceteris-paribus Profiles</a></span><ul class=\"toc-item\"><li><span><a href=\"#11.1-Introduction\" data-toc-modified-id=\"11.1-Introduction-8.1\">11.1 Introduction</a></span></li><li><span><a href=\"#11.2-Intuition\" data-toc-modified-id=\"11.2-Intuition-8.2\">11.2 Intuition</a></span></li><li><span><a href=\"#11.3-Method\" data-toc-modified-id=\"11.3-Method-8.3\">11.3 Method</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n",
    "## 1.1 Notes to readers \n",
    "\n",
    " Feedback can be given at the GitHub repo https://github.com/pbiecek/ema/issues. \n",
    "\n",
    "## 1.2 The aim of the  \n",
    "\n",
    "- 複雑なモデルはブラックボックスになってしまう。数千の説明変数がどのように予測に寄与しているかを理解するのは難しいか、不可能だ。複雑なモデルが期待したどおりに振る舞うとは限らない。\n",
    "\n",
    "- Cathy O’Neilは「ビックデータへの盲信はやめるべきだ」と主張する。\n",
    "    [Cathy O'Neil: The era of blind faith in big data must end ](https://www.ted.com/talks/cathy_o_neil_the_era_of_blind_faith_in_big_data_must_end)\n",
    "\n",
    "- 時間が経つと、パフォーマンスが悪くなったり、バイアスがかかってしまうモデル事例が増えている。  \n",
    "    この問題を解決するために新しい規制ができた。例えば、the General Data Protection Regulation (Gdpr 2018)である。  \n",
    "    \n",
    "- GDPRでは、自動化されたアルゴリズムのアウトプットに対して、説明を求める権利が認められている。\n",
    "\n",
    "- 機械学習とは、データの可用性とドメイン知識のトレードオフである。Flexible Modelは特徴量の良し悪しを判断するための学習に大量のデータを利用する。  \n",
    "    ドメインの理解より、コンピュータでのモデルトレーニングが重視されるようになっている。\n",
    "\n",
    "## 1.3  A bit of philosophy: three laws of model explanation \n",
    "\n",
    "- モデルを使うときに満たすべき３つのこと： \n",
    "    予測を裏付けるデータ自体の信憑性、予測に影響する説明変数は何か、１つの説明変数が変化した場合予測がどのように変化するかを推定できるか\n",
    "\n",
    "## 1.4  The structure of this book \n",
    "\n",
    "- 各章の内容\n",
    "\n",
    "## 1.5  Terminology \n",
    "\n",
    "- 機械学習と統計の専門用語の違い  \n",
    "\n",
    "## 1.6  Glass-box models vs. black-box models \n",
    "\n",
    "- A ,,glass-box’’ (sometimes called white-box or transparent-box) modelは、 ,,black-box’’とは反対のモデル。\n",
    "    すべての人にとって理解しやすく、限られた変数を使ってシンプルな構造になっている。\n",
    "\n",
    "- 分かりやすい構造で、変数も少ないモデルは、特定の説明変数が変わったときに予測がどう変化するのかを紐付けしやすい。\n",
    "    つまり、ドメイン知識に反したモデルを変えるのも容易である。\n",
    "\n",
    "## 1.7  Model-agnostic vs. model-specific approach \n",
    "\n",
    "- 異なる構造を持つモデルの優位性を比較説明するのは難しいので、アンサンブルで対応することがあるが、モデル構造に依存しない新しいアプローチが必要。 \n",
    "\n",
    "- p次元のベクトルを説明変数にし、単一のスコアや確率（実数）を返すモデルを想定してDalexを作成。\n",
    "\n",
    "## 1.8  What is in this book and what is not \n",
    "\n",
    "- 本の内容\n",
    "\n",
    "## 1.9  Acknowledgements \n",
    "\n",
    "- 謝辞、参考文献"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2  Model Development \n",
    "\n",
    "## 2.1 Introduction \n",
    "\n",
    "- 2章で説明すること：train済モデルを診断する前に、何を実行する必要があるか\n",
    "\n",
    "## 2.2 The Process \n",
    "\n",
    "【モデル構築の手順】 \n",
    "- 最も有名なモデル開発の方法はCRISP-DM (Chapman et al. 1999) 。  \n",
    "    ビジネスに対する理解→データに対する理解→データ収集→モデリング→評価→デプロイ\n",
    "- この本ではModel Development Process (Biecek 2019)を利用。  \n",
    "    問題の定式化、簡易なモデル化、チューニング、メンテナンス、終了（decommissioning. \n",
    "\n",
    "## 2.3 Notation \n",
    "\n",
    "【数学表記の説明】 \n",
    "\n",
    "## 2.4 Data exploration \n",
    "\n",
    "【データ可視化】の説明 \n",
    "\n",
    "## 2.5 Model training \n",
    "\n",
    "- モデルのトレーニングでは、ほとんどのアルゴリズムで以下の最適化問題を解いている。   \n",
    "  \n",
    "    $\\hat\\theta = \\arg \\underset{\\theta \\in \\Theta}{\\min}  L (y, f_\\theta(X)) + \\lambda(\\theta)$  \n",
    "  \n",
    "    モデルパラメータの$\\theta$ $=$ 損失関数$L (y, f_\\theta(X))$を最小化する$y,X$の集合 $＋$  モデルの複雑さを抑える正則化項$\\lambda(\\theta)$\n",
    "    \n",
    "\n",
    "## 2.6 Model understanding \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  \n",
    "|  \n",
    "省略  \n",
    "|   \n",
    "|   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Introduction to Instance Level Exploration\n",
    "\n",
    "- インスタンスレベルでの分析はモデル上での$x*$点を中心に３つの方法で分析する。  \n",
    "\n",
    "\n",
    "- variable attributions’’ approach(Chapter7-9)  \n",
    "    $x*$はモデルの平均予測とどう異なるか？  \n",
    "    \n",
    "    \n",
    "- the Local Interpretable Model-agnostic Explanations (LIME)(Chapter10)  \n",
    "    the curvature of the response surface around the point of interest$x∗$  \n",
    "    \n",
    "    \n",
    "- ,,What-If’’ analyses.(Chapter11-13)  \n",
    "    １つの説明変数が変わったらどのように予測が変わるか？  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Break-down Plots for Additive Attributions\n",
    "\n",
    "Break-down (BD) plotsについての説明  \n",
    "\n",
    "## 7.1 Intuition\n",
    "\n",
    "- 説明変数に条件をつけることで、説明変数$x$のモデル$f(x)$による予測への貢献度合いを計算する。\n",
    "\n",
    "-  ランダムフォレストモデルによるタイタニックデータの予測。\n",
    "\n",
    "- [BDPlots](https://pbiecek.github.io/ema/figure/break_down_distr.png)\n",
    "    - Panel A：変数を固定させたときの予測値の変化   \n",
    "        - all data : すべての乗客についての予測。  \n",
    "        - X =  : 各変数を固定していった場合の予測値の変化。例えばage=8の行はclassを１ｓｔに、ageを８に固定。\n",
    "        - 最後の行：各変数すべてを満たす乗客の予測になる。\n",
    "        - 黒い線：各乗客のデータが変数を固定することでどのように変化するか？          \n",
    "    - Panel B : 変数を固定させたときの平均予測値\n",
    "    - Panel C : 各変数の影響をポジティブ、ネガティブに分けてプロット。\n",
    "    \n",
    "## 7.2 Method\n",
    "\n",
    "### 7.2.1 Break-down for linear models（線形モデル（加法モデル？）について）\n",
    "\n",
    "- 以下の線形モデルを考える。  \n",
    "\n",
    "    $E_Y(y | x) = f(x) = \\beta^0 + x^1 \\beta^1 + \\ldots + x^p \\beta^p$\n",
    "\n",
    "\n",
    "- モデル$f(x)$の$x_*$点における予測値$f(x_*)$と、それに対する貢献度合い$v$は、以下の式で示される。  \n",
    "\n",
    "    - $f(x_*) = v_0 + \\sum_{j=1}^p v(j, x_*)$  \n",
    "        →　$v_0$（titanicでいうとすべての乗客のすべての説明変数を使った予測平均値）に、各説明変数の貢献度を足したもの  \n",
    "        \n",
    "    - $v(i, x_*) = \\beta^i (x^i_* - \\bar x^i)$  \n",
    "        →　係数×（入力値と入力平均値の差）、つまり線形モデル（加法モデル）における、各項の$x_*$点での予測と予測平均の差  \n",
    "    \n",
    "### 7.2.2 Break-down for a general case（線形モデル外も含む一般化）\n",
    "\n",
    "- $v(j, x_*)$を$j$番目の変数、instance $x_*$（titanicでいうと乗客$x_*$さん）に対する予測値とすると...\n",
    "\n",
    "\n",
    "- 貢献度合いを表す式  \n",
    "\n",
    "    $v(j, x_*) = E_X[f(X) | X^1 = x^1_*, \\ldots, X^j = x^j_*] - E_X[f(X) | X^1 = x^1_*, \\ldots, X^{j-1} = x^{j-1}_*]$\n",
    "    \n",
    "    $j$番目の説明変数の貢献度合いは、（$j$番目まで説明変数の入力があったときの$f(X)$の期待値）ー（$j-1$番目まで説明変数の入力があったときの$f(X)$期待値）といえる。  \n",
    "    <font color = 'red'>説明変数の順番に依存している</font>ので注意！  \n",
    "    \n",
    "    \n",
    "- 貢献度合いを表す別式  \n",
    "\n",
    "    $v(j, x_*) = \\Delta^{j|\\{1,  ..., j-1\\}}(x_*)$\n",
    "    \n",
    "    $j$が$｛1,...j-1｝$のときのモデル予測値の変化量\n",
    "\n",
    "\n",
    "- <font color = 'red'>順序の依存性を解決するための３つのアプローチ</font>\n",
    "    - <font color = 'red'>最も貢献度合いが高いものから順番に並び替える</font>\n",
    "    - <font color = 'red'>貢献度同士の相互作用を調べる（Chapter8）　→　iBreak-down</font>\n",
    "    - <font color = 'red'>すべての順序について貢献度を調べてその平均を取る（Chapter9）　→　SHAP</font>\n",
    "    \n",
    "    \n",
    "## 7.3 Example: Titanic data\n",
    "\n",
    "- 表7.1  \n",
    "    variable$j$だけを入力したときのモデルの期待値と、$v_0$（モデルの平均回答）からどのくらいのズレがあるか？\n",
    "\n",
    "- 表7.2  \n",
    "    variable$1,...,j$を順に入力していったときのモデルの期待値と、変数を増やしていったときの貢献度の増加量。\n",
    "\n",
    "## 7.4 Pros and cons\n",
    "\n",
    "- Break-Down plotsのメリット  \n",
    "    - コンパクトで分かりやすい。\n",
    "\n",
    "\n",
    "- Break-Down plotsのデメリット  \n",
    "    - <font color = 'red'>非加法モデルだとミスリードになる（説明変数の順番が大事になる）。</font>  \n",
    "    [参考：一般化線形モデル (GLM) & 一般化加法モデル(GAM)](https://www.slideshare.net/DeepLearningLab/glm-gam)  \n",
    "    - 説明変数が多くなると複雑になる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Break-down Plots for Interactions (iBreak-down Plots)\n",
    "\n",
    "- iBreak-down Plotsの説明。変数ペアも含めた貢献度を見る。\n",
    "\n",
    "## 8.1 Intuition\n",
    "\n",
    "- ageとclassの２つのみを使って生存率の変化を比較分析（Table8.1）\n",
    "\n",
    "- ageの影響度＋classの影響度＋誤差が２つの説明変数を使ったときの影響度。\n",
    "\n",
    "## 8.2 Method\n",
    "\n",
    "- モデル内部の相互作用は以下の順で識別される。\n",
    "    1. 説明変数ごとに予測値の変化量を個別に計算する。($O(p)$)\n",
    "    2. 説明変数のペア（$i,j$とする）による予測値の変化量ー$i$による予測値の変化量ー$j$による予測値の変化量を計算する。($O(p^2)$)\n",
    "    3. 重要度順に並び替える。（$O(p)$）\n",
    "\n",
    "## 8.3 Example: Titanic data\n",
    "\n",
    "- Table8.2\n",
    "    説明変数単体($\\Delta^{\\{i,j\\}|\\emptyset}(x_*)$）・説明変数のペア($\\Delta_{I}^{\\{i,j\\}}(x_*)$）について、影響度の絶対値が大きい順に並べ替えたもの。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 Shapley Additive Explanations (SHAP) and Average Variable Attributions\n",
    "\n",
    "- SHAPの説明。色々な順番で計算した重要度の平均を取る。\n",
    "\n",
    "## 9.1 Intuition\n",
    "\n",
    "- Figure9.1  \n",
    "    - BD plotsでの貢献度。変数の順番はランダム。変数をどのような順番にするかで、貢献度が違うことが分かる。\n",
    "\n",
    "- Figure９．２  \n",
    "    - Figure9.1で計算した１０個の順番に基づく貢献度について、平均を取ったもの（順番の影響を排除）。\n",
    "    - 赤と緑は各変数の貢献度。紫は異なる順番に並べたときの貢献度の分布。\n",
    "\n",
    "## 9.2 Method\n",
    "\n",
    "- SHAPはゲーム理論のShapley valueをモデルにしている。\n",
    "\n",
    "- Shapley value  \n",
    "    $\\displaystyle \\varphi(x_*,j) = \\frac{1}{p!} \\sum_{J} \\Delta^{j|\\pi(J,j)}(x_*)$\n",
    "    \n",
    "    - $\\varphi(x_*,j)$：すべての説明変数の重要度の平均値\n",
    "    - $\\pi(J,j)$：$j$番目の変数より前に位置する、$J$説明変数のセット\n",
    "    - $p!$：説明変数の集合が取りうる順列\n",
    "    \n",
    "## 9.3 Example: Titanic data\n",
    "\n",
    "- Titanicデータ、RandomForestで行った予測についてのSHAP値。\n",
    "\n",
    "## 9.4 Pros and cons\n",
    "\n",
    "- SHAPはDeepLIFT、Layer-Wise Relevance Propagation、LIMEにも活用されている。\n",
    "- SHAP値は加法モデル以外も通用するが（すべての順序の平均を取るため）、計算に時間がかかるためサンプリングをして使うと良い。\n",
    "\n",
    "## 9.5 Code snippets for R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Local Interpretable Model-agnostic Explanations (LIME)\n",
    "\n",
    "[参考：LIMEで機械学習の予測結果を解釈してみる](https://qiita.com/fufufukakaka/items/d0081cd38251d22ffebf)\n",
    "\n",
    "## 10.1 Introduction\n",
    "\n",
    "- Break-Down Plot, SHAPは説明変数が多いときには適切ではない。\n",
    "- ゲノム解析は画像処置のときはLIMEを使う。\n",
    "\n",
    "## 10.2 Intuition\n",
    "\n",
    "- Figure10.1\n",
    "    着目する（説明したい）予測（✚点）の周囲の点に人工のデータセットを配置。\n",
    "    データセットにglass-boxモデルを適用することで、局所的なモデルの振る舞いを近似して説明することができる。\n",
    "\n",
    "## 10.3 Method\n",
    "\n",
    "- LIMEの基本的な考え：以下の損失関数の最小化を考える。\n",
    "\n",
    "    $\\displaystyle \\hat g = \\arg \\min_{g \\in G} L(f, g, \\Pi_{x_*}) + \\Omega (g)$  \n",
    "\n",
    "\n",
    "- $f(x):\\mathcal X \\rightarrow \\mathcal R$　　\n",
    "    \n",
    "    black-box model。$\\mathcal X$は次元が大きい（p次元）、元々のデータ空間にある。\n",
    "    \n",
    "    \n",
    "- $g:\\mathcal X' \\rightarrow \\mathcal R$  \n",
    "\n",
    "    glass-box model。$\\mathcal X'$は次元が小さい（ｑ次元）、データ空間にある。\n",
    "\n",
    "### 10.3.1 Interpretable data representation\n",
    "\n",
    "- 高次元データによる予測の説明は難しいので、superpixelsに変換する。 （次元の圧縮）   \n",
    "    glass-box modelではsuperpixelに変換したデータを扱う。  \n",
    "\n",
    "- superpixelは０，１でoff,onを表す。  \n",
    "\n",
    "- superpixelは画像データでよく使われる。  \n",
    "\n",
    "### 10.3.3 Developing the glass-box model\n",
    "\n",
    "- LIMEでは、画像のどの点が（どのsuperpixelが）予測に寄与したかがわかる。\n",
    "\n",
    "## 10.4 Example: Titanic data\n",
    "\n",
    "- テーブルデータで使用する場合は、  \n",
    "    ①説明変数をグループ化する  \n",
    "    ②データをバイナリ変数に変換する（例　年齢：15歳未満・以上）  \n",
    "    のように、データを変換する必要がある。\n",
    "\n",
    "## 10.5 Pros and cons\n",
    "\n",
    "- pros  \n",
    "    モデルに依存しない、解釈可能な低次元にデータを圧縮する、局所的に元のblack-box modelによく似ている。\n",
    "    \n",
    "- cons  \n",
    "     データが連続変数のとき変換する必要がある→元のモデル予測の近似じゃない可能性も。  \n",
    "     注目すべき点（近似に使う）の周囲のどこにデータを配置するのか？で説明が変わる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 Ceteris-paribus Profiles\n",
    "\n",
    "## 11.1 Introduction\n",
    "\n",
    "- 11章は、選択した説明変数がどのようにモデルの予測に影響するかを説明する。\n",
    "- what-if分析は因果推論ではなく、探索的データ解析である。\n",
    "- 現実世界にモデルを当てはめるには因果推論が求められる。\n",
    "\n",
    "## 11.2 Intuition\n",
    "\n",
    "- Ceteris-paribus (CP) profilesとは  \n",
    "    各説明変数の曲率を調べることで、各説明変数がモデル応答にどう影響を与えるかを調べる。\n",
    "    多次元データを1次元に落とし込むことで可視化している。（Figure11.1）\n",
    "    \n",
    "## 11.3 Method\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
